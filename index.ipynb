{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Smart DRUGan\n",
    "(not exactly smart more like little bit less stupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Task\n",
    "Extent DRUGan in order to be able to provide a personalized Data Science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Roadmap\n",
    "at least what we've done\n",
    "- Research on existing solutions and resources \n",
    "- Define a source list of information\n",
    "- Define the structure the source should be mapped to\n",
    "- Define an NLP architecture for data processing\n",
    "- Create data scrappers\n",
    "- Join modules\n",
    "- Create interaction module with slack interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Source list\n",
    "- https://paperswithcode.com/\n",
    "- https://towardsdatascience.com/\n",
    "- https://becominghuman.ai/\n",
    "- http://www.arxiv-sanity.com/\n",
    "- https://www.analyticsvidhya.com/blog/\n",
    "- https://www.dataquest.io/blog/\n",
    "- https://www.kdnuggets.com/\n",
    "- http://blog.kaggle.com/\n",
    "- https://pythonprogramming.net/data-analysis-tutorials/\n",
    "- https://www.reddit.com/r/MachineLearning/\n",
    "- https://blog.openai.com/\n",
    "- https://machinelearningmastery.com/blog/\n",
    "- http://blog.yhat.com/\n",
    "- http://www.gitxiv.com/\n",
    "- https://deepmind.com/research/\n",
    "- https://code.fb.com/\n",
    "- http://www.fast.ai/\n",
    "- https://www.deeplearningweekly.com/\n",
    "- https://eng.uber.com/\n",
    "- http://news.mit.edu/topic/machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example of a mapping structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "{\"someblog.com\":\n",
    "    {   \n",
    "        \"source\":7,\n",
    "        \"title\":\"New tyoe of robotics\", \n",
    "        \"time_to_read\":\"approximately 40 minutes\",\n",
    "        \"short_summary\":\"Some lines\",\n",
    "        \"our_tags\": [\"ML\", \"NLP\"],\n",
    "        \"given_by_blog_tags\":[\"Disussion\",\"Project\",\"Reserch\"],\n",
    "        \"date\": \"19 Sep 2018\",\n",
    "        \"author_name\": \"name\", \n",
    "        \"number_of_comments\":34, \n",
    "        \"preview_picture\":\"Here will be a png\" ,\n",
    "        \"github_link\":\"https://github.com/\",\n",
    "        \"arxiv_link\":\"https://arxiv.org/abs/1807.02033v2\",\n",
    "        \"reddit_link\":\"https://www.reddit.com/r/MachineLearning/comments/\",\n",
    "        \"amount_of_facebooks\":450,\n",
    "        \"amount_of_twits\":450\n",
    "    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Defying NLP architecture in our case consists of:\n",
    "- Making a good enough tagger\n",
    "- Realizing an article summarization and a time estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tagger\n",
    "![](img/maxresdefault.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What do we have in tagger \n",
    "- A list of all DS terms\n",
    "- Automatic Keyphrase Extraction technology\n",
    "- Function that checks whether found keyphrase is a DS term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A list of all DS terms\n",
    "At the beginning it wasn't a list but a 2350 lines dictionary with an hierarchical structure  \n",
    "Fragment of that dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dict = {'ai_projects' :{ \n",
    "    'automated mathematician': {},\n",
    "    'allen': {},\n",
    "    'open mind common sense': {},\n",
    "    'mindpixel': {},\n",
    "    'cognitive assistant that learns and organizes': {},\n",
    "    'blue brain project': {},\n",
    "    'google deepmind': {},\n",
    "    'human brain project': {},\n",
    "    'ibm watson group': {}\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Automatic Keyphrase Extraction(terminology extraction)\n",
    "- It seems like a very hard task and it is true but thankfully while trying to get it done we found a ready to use library named textacy.\n",
    "- However, that wasn't the end and we faced a new problem of chosen a right extraction method (from 8 existing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Finishing up our tagger\n",
    "- Mesuaring hamming a distance between found keyphrase and terms from our list\n",
    "- If found close enough term from list, we declare it as a TAG(close enough = preset threshold)\n",
    "- Than we again mesuare a hamming distance but now between our tags to get rid of simillar ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summarization and a time estimation\n",
    "![](img/clock.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Time estimation and readability\n",
    "- Time estimation counted through simple medium formula where we just divide number of words by average WPM and every picture adds 12 seconds\n",
    "- Readability counted through more complex Flesch reading ease formula \n",
    "![](img/Flesch-Reading-Ease-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summarization\n",
    "We've used a library called sumy which has a whole bunch of summarizers and challenge was to choose the right one.  \n",
    "We've ended up choosing Luhn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(слайды мариам)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Joining modules\n",
    "- Combining all parts of the script\n",
    "- Сonnecting script to the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks for attention!\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
